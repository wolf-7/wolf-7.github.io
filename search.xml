<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Install And Configure Grafana/influxdb ON AWS EC2 Instance(Ubuntu)]]></title>
    <url>%2F2018%2F05%2F29%2F%E6%90%AD%E5%BB%BAgrafana-on-AWS-Ubuntu-Instance%2F</url>
    <content type="text"><![CDATA[需求：因AWS自带的CloudWatch监控不能满足当下需求，所以使用适用于AWS CloudWatch的Grafana仪表板. &emsp; 一些有用的资料 Grafana官方安装文档InfluxDB安装文档GitHub提供的监控AWS的一些基础服务模板 添加AWS Redshift dashboard 1.因为Grafana官方网站提供的模板中没有针对Redshift监控的模板，只能自己动手丰衣足食了； 2.在variable添加Region、ClusterIdentifier以便于可以在dashboard中自定义选择区域与集群名称； 3.配置dashboard的时候，在metrics中引用定义的variable； 4.在配置dashboard展示的时候，在添加Axes、Legend、Display的时候，需要注意一些细节，如果配置错误，展示会混乱， 比如在Axes配置network展示单位需要使用data rate中的bytes/sec，CPU or disk 展示需要使用none中的percent。 如果想在dashboard右下角显示最大、最大、当前等数据，需要在Legend开启Show/Max/Min/As Table/Avg/Current。 Display是控制以line或者其他方式显示，Fill是颜色的深浅，line Width是line的加粗。]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置适用于Lambda函数的AWS环境NAT网关-从VPC访问Intelnet公共网络]]></title>
    <url>%2F2018%2F02%2F06%2F%E9%85%8D%E7%BD%AE%E9%80%82%E7%94%A8%E4%BA%8ELambda%E5%87%BD%E6%95%B0%E7%9A%84AWS%E7%8E%AF%E5%A2%83NAT%E7%BD%91%E5%85%B3-%E4%BB%8EVPC%E8%AE%BF%E9%97%AEIntelnet%E5%85%AC%E5%85%B1%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[需求：因为lambda本身在建立之初是具备公共的Intelnet访问权限的，但是因为架构需要VPC，配置VPC以后Lambda函数将失去公共的Intelnet访问权限，此时需要给VPC配置NAT网关，同时需要在安全组中添加需要出站的连接（默认是全部允许出站） &emsp; AWS官方提供的NAT网关架构图 AWS官方技术文档 相关AWS技术知识点 1.这里涉及到AWS云的几个知识点：VPC、子网、Intelnet网关、NAT网关。 2.默认官方文档架构中是分为Public与Private俩个子网段，我的环境是已经 存在VPC与Public子网段，因此，这里只涉及到了Private网段。 配置VPC 1.VPC默认是会存在，这里会涉及到各个AWS服务的VPC关联问题，如果新建VPC， 会导致其他VPC与Lambda或其他服务无法访问等未知问题，所以，不建议在创建 新的VPC，而是在原有的VPC中创建子网，然后配置NAT网关。 2.默认VPC中存在了Subnet子网段: 1172.31.0.0/16 以下我们将在这个VPC中创建Subnet子网。 创建VPC中的Subnet子网 1.新建NAT网关的子网，这里面涉及到网络的一些基础概念，子网划分，需要了解。 默认VPC存在了三个子网为: 123172.31.0.0/20(0-15)172.31.16.0/20(16-31)172.31.32.0/20(32-47) 2.所以为了方便区分，我们需要创建一个命名subnet-lambda的子网: 1172.31.48.0/20(48-63) 作为NAT网关需要使用的子网段。 配置Intelnet网关 1.创建VPC时会自动创建Intelnet网关并且自动attached，为AWS提供的公共Intelnet访问。 2.如果是新建的VPC，就需在新建一个Intelnet网关，并且attached到创建的VPC上。 配置NAT网关 1.新建NAT网关，将其关联到一个可已经配置Intelnet网关的子网。 2.创建一个ElasticIP，attached到NAT网关。 配置Route表 1.在路由表需要创建一个Route表（rtb-default），一般会创建默认Route表，自动关联， 这时将上面新建的Intelnet网关标记到默认Route表，并关联已经创建的VPC中的三个子网。 2.新建一个Route表（rtb-lambda），关联172.31.48.0/20子网段。 将路由标记为0.0.0.0/0 --&gt;&gt; nat-gateway-id（新建的NAT网关）。 配置Lambda函数 1.Lambda函数需要具有对VPC的执行Read权限，需要在IAM中添加赋予。 2.配置网络为新建VPC中的子网（172.31.48.0/20）。 3.开启需要入站、出站的安全组。 此时，Lambda函数就具备了Intelnet公共访问权限了。]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[做一个职业运维人]]></title>
    <url>%2F2018%2F01%2F01%2F%E5%81%9A%E4%B8%80%E4%B8%AA%E8%81%8C%E4%B8%9A%E8%BF%90%E7%BB%B4%E4%BA%BA%2F</url>
    <content type="text"><![CDATA[很多三四年工作经验的同学，因为缺少必要的职业素养的培训，工作的方式方法或多或少存在一些问题，这影响了自身的职业发展。怎么做才算是会工作，这里有几点不成熟的建议，供诸君参考。 搞清楚公司为什么聘请你公司不是慈善机构，而是以营利为目的，公司聘请你，就是为了让你帮助公司去营利，帮助公司解决问题。所以，如果觉得自己在公司没啥用处，有你没你没区别，那就离解聘不远了。 不断升职加薪的秘诀要不断有产出，变成稀缺人才。要想明白自己可以帮公司解决什么问题，帮领导解决什么问题。并不遗余力的去拼搏，相信我，领导看得见你的付出。某些事情你可以做，别人做不了，领导把事情交到你这他放心，你就离加薪不远了，多次如此，就离升职不远了。 把握好跟领导的关系从某种程度上讲，你其实不是在为公司打工，而是在为你的直属上司打工。所以，跟领导的关系尽量不要搞砸了，领导说的对的，要全力支持；做的不合理的，要#### 私下#### 跟领导沟通，用委婉的方式帮他指出问题所在。如果很不幸，你的领导刚愎自用，听不进谏言，那我只能说，良禽择木而栖。 把握好跟同事的关系由于每个人的认知不同，背景知识不同，经验不同，在同一件事情上面的看法会不同，这将是常态。本着理不辨不明的原则，凡事沟通解决，对事不对人，注意表达语气。在这个团体作战的年代，如果你不合群，也会让你的领导难办。只要结果是好的，忍让一下又何妨。 不断提升自身的软素质在职业生涯前期，专业技术能力是推升你往上走的主要动力，职业生涯中期，软素质就会显得尤为重要，职业生涯后期，人格魅力和影响力是不可或缺的。 蓝图规划、目标拆解、关键路径、过程管理如果只是低头走路，不抬头看方向，容易迷失。工作也是一样，作为员工，要去了解公司战略，部门蓝图，做为领导，要去传达公司战略，部门蓝图，这样，整个团队才知道往哪使劲。把公司目标拆成部门目标，把部门目标拆成团队目标，最后拆成个人目标，了解这些，工作方向才能比较清晰。为了达成目标，我们制定了关键路径，项目、任务都是为目标服务的。老板要你写周报，要你经常汇报，实际就是在做过程管理，怕出意外~ 知道方向了要低头看路我们有理想，知道最佳实践，但要想真正落地，还需要知道现状，知道从现实走向理想的路。脱离一线的高层容易活在理想里，我们作为干活的人，却不能靠理想，靠方法论活着，制定出这条路，然后将路的走法同步给你的老板，得到老板的认可，坚定的沿着这条路走下去，才能最终达成目标。 念念不忘必有回响全身心的投入，你会发现自己的能量超乎想象。不知道大家有没有这样的经历，工作中遇到一个问题，百思不得其解，然后你走着想，做着想，吃饭想，睡前想，然后某天早上醒来，灵光乍现，得出一完美方案。忍不住都要为自己的聪明才智鼓鼓掌，这就是念念不忘必有回响。老天眷顾努力的人。 过程中要及时反馈，经常汇报工作中，我们要想领导之所想，老板把任务拆解好了，跟大伙制定了达成目标的关键路径，手下人去干活了，接下来老板会关注什么？显然，老板想知道各位干得如何了，是否遇到难点，出现意外，影响项目进展，已经做了哪些，还差哪些……所以，及时反馈，经常汇报是很有必要滴，老板会觉得你很上进，很积极。但老是拿个PPT去给老板讲，很不系统化，也不便于老板跟踪，一个良好的项目管理工具是很有必要的。]]></content>
      <categories>
        <category>职业规划</category>
      </categories>
      <tags>
        <tag>职业规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维的价值与目标拆解]]></title>
    <url>%2F2017%2F07%2F17%2F%E8%BF%90%E7%BB%B4%E7%9A%84%E4%BB%B7%E5%80%BC%E4%B8%8E%E7%9B%AE%E6%A0%87%E6%8B%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[这里说的运维主要是指应用运维，非系统部的偏硬件和网络的运维 我不幸福很多运维同学感觉自己很苦逼，感觉每天都在救火，给研发擦屁股，做一些重复工作，做一些对自己提升较小的事情，总结一句话，就是不幸福。 怎么幸福工作中的幸福主要来自两点： 1、有成就感；2、薪水到位； 而薪水到位与否很大程度决定于你的产出（如果你的老板不懂你们的工作，看不到本该看到的价值，那另当别论），而产出多少很大程度上和你的成就感是正相关的，所以要幸福，就要做有成就感的事情。 谈成就感作为一个技术人员，成就感主要来自两点： 1、做的有价值2、被别人认同 对于研发同学，比如写了一个framework，或者lib，同事都说好，并拿去用，这个时候是超级有成就感的；或者做的产品被市场认可，被同行认可，也是很有成就感的。 那运维同学呢？价值体现在哪里？ 运维的价值可以分对内的，和对外的。比如运维同学写了一些运维工具，大大提升了做某些事情的效率，得到周边同学的认可，这是对内的价值。这里，笔者更希望好好探讨一下对外的价值，运维这个角色，在公司的定位，对公司的价值。 多数公司在创业之初，是没有运维这个角色的，相关工作内容由所谓的全栈工程师、栈溢出工程师代劳。随着公司规模扩大，机器到几百台，会暴露出N多问题，比较直观的比如： 线上环境混乱不堪，OS发行版、系统参数配置、WEB服务器、启停方式、部署路径全凭各服务的研发人员的喜好和熟悉程度 监控各种不完备，很多故障都是后于用户发现，有些进程挂了好久才偶然发现或用户报障了才发现 出了故障排查费劲，甚至在线上调试 很多故障都是由一些低级问题导致，比如ulimit配置不合理，比如想回滚却发现忘记备份 服务器资源利用率低，很多机器根本没在用，甚至都找不到了，浪费了大量硬件成本 同时操作大量机器缺乏有力工具，线上权限要么混乱不堪，要么所有人有所有机器的权限 技术合伙人意识到：靠专注写业务逻辑的研发人员来解决这些问题是不靠谱的，需要设置一个新的职能团队来收拾这个烂摊子。 于是，运维团队应运而生，定位就是：解决上面提到的问题。换个说法：让研发只专注业务逻辑和架构设计，运维搞定剩下的。这样会带来以下好处： 产品更快得到验证：解放了研发人力，研发同学就可以全身心扑在产品开发上，迭代速度会变快 大幅提升服务稳定性：专业的人干专业的事，线上环境规范干净了，监控完备了，没有低级错误了，系统参数配置合理了 资产得到有效利用：资产专门有人在梳理，通过服务混部等手段提高利用率，再也没有机器在空转 用一句话来概况运维的价值: 花更少的钱，让产品更快迭代，更稳定运行 &emsp;有些运维同仁概况了运维九字真言“安全稳定高效低成本”，说的非常到位。其中的安全，行文到此尚未介绍到，有些公司会把安全单拎出来成立安全部，有些就直接放在运维团队，这个看公司情况，如果公司体量大，个人认为，还是单拎出来会好一些。 目标拆解安全、稳定、高效、低成本，怎么才能把这四大目标做好？应该做哪些事情来达成目标？笔者用一张脑图来梳理一下： 运维目标拆解]]></content>
      <categories>
        <category>职业规划</category>
      </categories>
      <tags>
        <tag>职业规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Red Hat Certified Engineer (RHCE) EX300 Study Guide]]></title>
    <url>%2F2017%2F03%2F02%2FRed-Hat-Certified-Engineer-RHCE-EX300-Study-Guide%2F</url>
    <content type="text"><![CDATA[Red Hat Certified Engineer (RHCE) EX300 Study Guide. If you’re studying towards RHCE, then you may find this page useful. Our configuration was tested on RHEL 7.0 and RHEL 7.1, some notes for the newest at the time of writing RHEL 7.2, have also been added, were available. There is a link to a sample exam available at the bottom of the page. I also recommend you checking out the following blogs: CertDepot and RootUsers. They contain a great deal of information that can be helpful preparing for the RHCE exam. RHCE exam candidates should be able to accomplish the following without assistance. System Configuration and Management Use network teaming or bonding to configure aggregated network links between two Red Hat Enterprise Linux systems Configure IPv6 addresses and perform basic IPv6 troubleshooting Route IP traffic and create static routes Use firewalld and associated mechanisms such as rich rules, zones and custom rules, to implement packet filtering and configure network address translation (NAT) Use /proc/sys and sysctl to modify and set kernel runtime parameters Configure a system to authenticate using Kerberos (sssd, nslcd) Configure a system as either an iSCSI target or initiator that persistently mounts an iSCSI target Produce and deliver reports on system utilisation (processor, memory, disk, and network) Use shell scripting to automate system maintenance tasks Network ServicesNetwork services are an important subset of the exam objectives. RHCE candidates should be capable of meeting the following objectives for each of the network services listed below: Install the packages needed to provide the service Configure SELinux to support the service Use SELinux port labeling to allow services to use non-standard ports Configure the service to start when the system is booted Configure the service for basic operation Configure host-based and user-based security for the service HTTP/HTTPS Configure a virtual host Configure access restrictions on directories Deploy a basic CGI application Configure group-managed content Configure TLS security DNS Configure a caching-only name server Troubleshoot DNS client issuesNFS Provide network shares to specific clients Provide network shares suitable for group collaboration Use Kerberos to control access to NFS network sharesSMB Provide network shares to specific clients Provide network shares suitable for group collaborationSMTP Configure a system to forward all email to a central mail serverSSH Configure key-based authentication Configure additional options described in documentationNTP Synchronise time using other NTP peersDatabase services Install and configure MariaDB Backup and restore a database Create a simple database schema Perform simple SQL queries against a database Other RHCE Related TopicsFreeIPA Server on RHEL 7Configure Remote Logging on RHEL 7Software Bridge on Top of a Teamed Device on RHEL 7 RHCE Sample Exam for RHEL 7I’ve created a sample exam, it’s available here.]]></content>
      <categories>
        <category>RHCE</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MySQL备份工具Mysqldump以及Xtrabackup详解]]></title>
    <url>%2F2017%2F02%2F07%2FMySQL%E5%A4%87%E4%BB%BD%E5%B7%A5%E5%85%B7mysqldump%E4%BB%A5%E5%8F%8AXtrabackup%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[开头语: 在开始对Mysqldump跟Xtrabakcup的介绍与使用方法到之前，说下数据对公司的重要性：123对于公司来讲，数据库本身可能并不重要，重要的是数据库中存储的数据。对于备份来讲，最终的目的是可以使用备份能够实现还原数据库中的数据。因此，一个可恢复的数据库备份是非常重要的，甚至关乎公司的命脉。 为什么备份? 12345实现灾难恢复：硬件故障(冗余)、软件故障(BUG)、自然灾害、黑客攻击、误操作、...测试恢复备份时，可能出现将数据库测试崩溃掉的情况这里最可能出现的情况是：误操作所以说，在操作数据库时，一定要慎之又慎 备份时需要注意的事项 注意事项 1234567能容忍最多丢失多少数据；恢复数据需要在多长时间内完成；需要恢复哪些数据；做恢复演练： 测试备份的可用性； 增强恢复操作效率； 备份需要考虑的因素 1234锁定资源多长时间？备份过程的时长？备份时的服务器负载？恢复过程的时长？ 备份什么? 1234数据二进制日志、InnoDB的事务日志；代码（存储过程、存储函数、触发器、事件调度器）服务器的配置文件 --&gt; 配置系统中的配置文件 --&gt; 存放在 Git 、svn 上 注意：二进制日志、InnoDB事务日志 与数据要分别存放在不同的硬盘中 备份策略 1234全量+差异 + binlogs全量+增量 + binlogs 备份手段：物理、逻辑 备份类型 备份的数据的范围123完全备份和部分备份 完全备份：整个数据集； 部分备份：数据集的一部分，比如部分表； 全量备份、增量备份、差异备份 全量备份 1备份整个数据库的所有数据 增量备份 1仅备份自上一次完全备份或 增量备份以来变量的那部数据 差异备份 1仅备份自上一次完全备份以来变量的那部数据；(浪费空间，还原效果比增量快) 通过备份恢复数据库 12完全+增量： 完全+每一次增量 + 二进制日志(根据时间点恢复)完全+差异： 完全+最后一次差异备份 + 二进制日志(根据时间点恢复) 物理备份、逻辑备份 物理备份 1直接复制数据文件进行的备份 逻辑备份(mysqldump) 12通过mysql，从数据库导出数据另存在一个或多个文件中通过一个大的SELECT 语句，转成一个 INSERT 语句 进行备份 热备、温备、冷备 热备 1读写操作均可进行的状态下所做的备份 --&gt; 导致备份的数据时间点可能不一致，恢复后的数据时间点不一致 --&gt; 导致MySQL拒绝恢复 温备 1可读但不可写状态下进行的备份 冷备 1读写操作均不可进行的状态下所做的备份 mysqldump备份工具使用详解 备份策略： 1全量备份 + binlogs 命令详解 语法格式： 123mysqldump [OPTIONS] database [tables]OR mysqldump [OPTIONS] --databases [OPTIONS] DB1 [DB2 DB3...]OR mysqldump [OPTIONS] --all-databases [OPTIONS] 实例详解： 12345# 表级别备份；不会自动创建数据库$ mysqldump mydb# 库级别备份，自动创建数据库 $ mysqldump --databases mydb 选项详解 12345678910111213-x, --lock-all-tables 锁定'所有库的所有表'，读锁；-l, --lock-tables 锁定'指定库所有表'；-R, --routines 备份存储过程和存储函数；-E, --events 备份事件调度器-F，--flush-logs 锁定表完成后，即进行日志刷新操作，让日志滚动；--triggers 备份触发器--master-data[=#] ：记录备份开始时 binlog中 1：记录为CHANGE MASTER TO语句，此语句不被注释； 2：记录为CHANGE MASTER TO语句，此语句被注释； 'InnoDB存储引擎：支持温备和热备；' --single-transaction：'创建一个事务，基于此快照执行备份'； 全量备份一次整个数据库 开启二进制日志 1234$ vim /etc/my.cnf.d/server.conf[server]log_bin=mysql-bin$ systemctl restart mariadb.service 开始备份数据库 123456789101112131415161718192021222324252627# 使用mysqldump备份整个mysql数据库$ mysqldump -E -R --triggers --master-data=2 -F -l --single-transaction --all-databases &gt; /tmp/all-fullback-$(date +%F).sql# 登陆至MySQL修改一些数据$ mysql &gt; SHOW MASTER LOGS;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 30352 || mysql-bin.000002 | 1038814 || mysql-bin.000003 | 9235 || mysql-bin.000004 | 696 || mysql-bin.000005 | 245 |+------------------+-----------+&gt; use hellodb;&gt; DELETE FROM students WHERE StuID=1;&gt; DELETE FROM students WHERE StuID=5;&gt; DELETE FROM students WHERE StuID=10;&gt; DELETE FROM students WHERE StuID=15;&gt; DELETE FROM students WHERE StuID=20;# 拷贝全量备份后，未备份的二进制日志至/tmp目录中$ cp /var/lib/mysql/mysql-bin.000005 /tmp/# 模拟数据库崩溃情况，删除数据库数据目录下的所有文件$ rm -rf /var/lib/mysql/* 使用备份恢复数据库 重启数据库 12$ systemctl stop mariadb.service$ systemctl start mariadb.service 登陆数据库进行恢复 123456$ mysql# 关闭会话级别的二进制日志，因为我们需要执行恢复sql脚本，不希望二进制记录此信息&gt; SET @@session.sql_log_bin=OFF; # 在MySQL中执行SQL脚本&gt; \. /tmp/alldb_fullbackup-2017-06-20.sql 使用二进制日志恢复未备份的信息 12$ cd /tmp$ mysqlbinlog mysql-bin.000005 | mysql 开启二进制日志记录 1&gt; SET @@session.sql_log_bin=ON; 至此，一次删库到恢复就完成了，不过要注意的是，在恢复完成后，如果业务不是很着急需要上线，这时还要做一次全量备份。如果业务必须立即上线，我们也可以在当天晚上进行备份数据库。 使用备份脚本备份数据库12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364$ vim mysql-backup.sh#!/bin/bash# MYSQLDBUSERNAME是MySQL数据库的用户名，可自定义MYSQLDBUSERNAME=root# MYSQLDBPASSWORD是MySQL数据库的密码，可自定义MYSQLDBPASSWORD="root@123"# MYSQBASEDIR是MySQL数据库的安装目录，--prefix=$MYSQBASEDIR，可自定义MYSQBASEDIR=/usr# MYSQL是mysql命令的绝对路径，可自定义MYSQL=$MYSQBASEDIR/bin/mysql# MYSQLDUMP是mysqldump命令的绝对路径，可自定义MYSQLDUMP=$MYSQBASEDIR/bin/mysqldump# BACKDIR是数据库备份的存放地址，可以自定义修改成远程地址BACKDIR=/var/backup/mysqldb# 获取当前时间，格式为：年-月-日，用于生成以这种时间格式的目录名称DATEFORMATTYPE1=$(date +%Y-%m-%d)# 获取当前时间，格式为：年月日时分秒，用于生成以这种时间格式的文件名称DATEFORMATTYPE2=$(date +%Y%m%d%H%M%S)# 数据库数据目录MYSQDATADIR=/var/lib/mysql# 如果mysql命令存在并可执行，则继续，否则将MYSQL设定为mysql，默认路径下的mysql[ -x $MYSQL ] || MYSQL=mysql# 如果mysqldump命令存在并可执行，则继续，否则将MYSQLDUMP设定为mysqldump，默认路径下的mysqldump[ -x $MYSQLDUMP ] || MYSQLDUMP=mysqldump# 如果不存在备份目录则创建这个目录[ -d $&#123;BACKDIR&#125; ] || mkdir -p $&#123;BACKDIR&#125;[ -d $&#123;BACKDIR&#125;/$&#123;DATEFORMATTYPE1&#125; ] || mkdir $&#123;BACKDIR&#125;/$&#123;DATEFORMATTYPE1&#125;# 获取MySQL中有哪些数据库，根据mysqldatadir下的目录名字来确认，此处可以自定义，TODODBLIST=`ls -p $MYSQDATADIR | grep / |tr -d /`# 从数据库列表中循环取出数据库名称，执行备份操作for DBNAME in $DBLIST # mysqldump skip one table # -- Warning: Skipping the data of table mysql.event. Specify the --events option explicitly. # mysqldump --ignore-table=mysql.event # http://serverfault.com/questions/376904/mysqldump-skip-one-table # --routines，备份存储过程和函数 # --events，跳过mysql.event表 # --triggers，备份触发器 # --single-transaction，针对InnoDB，在单次事务中通过转储所有数据库表创建一个一致性的快照，此选项会导致自动锁表，因此不需要--lock-all-tables # --flush-logs，在dump转储前刷新日志 # --ignore-table，忽略某个表，--ignore-table=database.table # --master-data=2 ，如果启用MySQL复制功能，则可以添加这个选项 # 将dump出的sql语句用gzip压缩到一个以时间命名的文件 do $&#123;MYSQLDUMP&#125; --user=$&#123;MYSQLDBUSERNAME&#125; --password=$&#123;MYSQLDBPASSWORD&#125; --routines --events --triggers --single-transaction --flush-logs --ignore-table=mysql.event --databases $&#123;DBNAME&#125; | gzip &gt; $&#123;BACKDIR&#125;/$&#123;DATEFORMATTYPE1&#125;/$&#123;DBNAME&#125;-backup-$&#123;DATEFORMATTYPE2&#125;.sql.gz # 检查执行结果，如果错误代码为0则输出成功，否则输出失败 [ $? -eq 0 ] &amp;&amp; echo "$&#123;DBNAME&#125; has been backuped successful" || echo "$&#123;DBNAME&#125; has been backuped failed" # 等待5s，可自定义 /bin/sleep 5done xtrabackupex备份工具使用详解安装xtrabackupex官方下载地址：XtraBackup 安装XtraBackup 123$ ntpdate 172.16.0.1$ wget ftp://172.16.0.1/pub/Sources/7.x86_64/percona/percona-xtrabackup-24-2.4.7-2.el7.x86_64.rpm$ yum install -y ./percona-xtrabackup-24-2.4.7-2.el7.x86_64.rpm 进行一次全库备份1234567891011$ vim /etc/my.cnf.d/server.conf[server]skip_name_resolve=ONinnodb_file_per_table=ONlog-bin=mysql_bin$ systemctl start mariadb.service# 全库备份时，无需指定数据库即可备份。指定库备份使用 --databases DATABASE_NAME$ innobackupex --user root /data/backup/$ ll /data/backup/2017-07-13_20-05-42/ 通过备份恢复数据库 恢复之前的准备 123# 默认数据库损坏，被删库$ cp /var/lib/mysql/mysql_bin.00000* /data/backup$ rm -rf /var/lib/mysql/* 执行Preparing操作 1$ innobackupex --apply-log /data/backup/2017-07-13_20-05-42/ 恢复数据库 123$ innobackupex --copy-back 2017-07-13_20-05-42/$ cd /var/lib/mysql$ chown -R mysql.mysql ./* 启动数据库 12$ systemctl start mariadb.service$ mysql 备份后生成的一些文件 增量备份 数据库(全库)增量备份：仅备份自上一次完全备份或增量备份以来变量的那些数据 先做一次全量备份 1$ innobackupex --user root /data/backup 连接到数据库中，删除/增加一些数据，为一会做增量备份打下基础 12345$ mysql&gt; use hellodb;&gt; DELETE FROM students WHERE StuID=21;&gt; INSERT INTO students (Name,Age,Gender,ClassID,TeacherID) VALUES('Zhu Ba Jie',120,'M',2,3);&gt; exit; 第一次增量备份 1$ innobackupex --incremental -u root /data/backup --incremental-basedir=/data/backup/2017-07-13_20-38-20/ 再次连接到数据库，删除修改一些数据，再做第二次增量备份 1234$ mysql &gt; use hellodb;&gt; DELETE FROM students WHERE StuID=1;&gt; EXIT; 第二次增量备份 12345678910111213141516171819# 这里--incremental-basedir 为上一次增量备份的目录，而非全量备份的目录$ innobackupex -u root --incremental /data/backup --incremental-basedir=/data/backup/2017-07-13_20-47-49# 第二次增量的checkpoints$ cat 2017-07-13_20-56-20/xtrabackup_checkpointsbackup_type = incrementalfrom_lsn = 1638999to_lsn = 1640148last_lsn = 1640148compact = 0recover_binlog_info = 0# 第一次增量的checkpoints$ cat 2017-07-13_20-47-49/xtrabackup_checkpointsbackup_type = incrementalfrom_lsn = 1636913to_lsn = 1638999last_lsn = 1638999compact = 0recover_binlog_info = 0 通过两次增量备份 + 全量备份 进行恢复数据库的操作 12345678910111213141516171819202122232425262728293031323334353637383940# 删库$ cp /var/lib/mysql/mysql_bin.* /data/backup/binlogs$ rm -rf /var/lib/mysql/*1.合并增量备份(只提交不回滚)# 只提交不回滚 全量备份$ innobackupex --apply-log --redo-only 2017-07-13_20-38-20/# 只提交不回滚 第一次增量+全量$ innobackupex --apply-log --redo-only 2017-07-13_20-38-20 --incremental-dir=2017-07-13_20-47-49# 只提交不回滚 第二增量+全量(第一次增量+全量)$ innobackupex --apply-log --redo-only 2017-07-13_20-38-20 --incremental-dir=2017-07-13_20-56-202.开始提交并回滚$ innobackupex --apply-log 2017-07-13_20-38-20/3.拿着提交并回滚后的全量，进行恢复$ innobackupex --copy-back 2017-07-13_20-38-20/4.查看恢复后的数据目录$ ll /var/lib/mysql total 40988drwxr-x--- 2 root root 4096 Jul 13 21:17 2017-07-13_20-27-08drwxr-x--- 2 root root 4096 Jul 13 21:17 hellodb-rw-r----- 1 root root 18874368 Jul 13 21:17 ibdata1-rw-r----- 1 root root 5242880 Jul 13 21:17 ib_logfile0-rw-r----- 1 root root 5242880 Jul 13 21:17 ib_logfile1-rw-r----- 1 root root 12582912 Jul 13 21:17 ibtmp1drwxr-x--- 2 root root 4096 Jul 13 21:17 mysqldrwxr-x--- 2 root root 4096 Jul 13 21:17 performance_schemadrwxr-x--- 2 root root 4096 Jul 13 21:17 test-rw-r----- 1 root root 23 Jul 13 21:17 xtrabackup_binlog_pos_innodb-rw-r----- 1 root root 532 Jul 13 21:17 xtrabackup_info5.修改目录权限$ chown -R mysql.mysql /var/lib/mysql/* 结束语: 对于Mysqldump跟Xtrabakcup的介绍与使用方法到此完成。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Optimise MySQL Configuration for WordPress]]></title>
    <url>%2F2017%2F02%2F07%2FOptimise-MySQL-Configuration-for-WordPress%2F</url>
    <content type="text"><![CDATA[Document links]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何接受一个新业务的运维工作？]]></title>
    <url>%2F2016%2F05%2F02%2F%E5%A6%82%E4%BD%95%E6%8E%A5%E5%8F%97%E4%B8%80%E4%B8%AA%E6%96%B0%E4%B8%9A%E5%8A%A1%E7%9A%84%E8%BF%90%E7%BB%B4%E5%B7%A5%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[对丑话说前头：先跟研发leader沟通，灌输运维理念，丑话说在前头，我们不做保姆式运维，我们会致力于线上服务安全、稳定、低成本、快速迭代，从运维视角提高产品力。开发机、测试环境，研发自己搞，我们可以协助帮忙，做专业的咨询服务，想让我们直接操刀开发环境的变更，免谈！ 业务概要了解了解业务相关的人，对应的研发同学、研发leader、测试同学、测试leader、产品经理分别是谁，联系方式存下来，拉个群，出了问题可以找到对应的人。 了解服务是干啥的，解决了什么问题，业界有对标的开源产品吗，方便我们快速认识这个产品。 了解服务的上下游，依赖哪些服务，哪些服务依赖我，对应的接口人是谁，这里先简单了解一下即可。 了解服务部署情况，部署在哪些机房，用什么语言编写的，基础网络、专线带宽、机房出口是否靠谱，是否曾因基础设施导致过问题，当前主要痛点是什么。 业务串讲要求研发同学（或者上一任运维同学）准备PPT，做一个业务串讲，讲解一些研发同学希望传达给运维同学的信息，讲解一些运维同学希望从研发这得到的信息。比如：详细部署拓扑、服务整体架构、数据流、提测变更流程、监控方式、部署到了哪些机器、机器登录方式、每个机器上是什么模块、OS参数是否有调优，考量是什么、用到了哪些第三方软件，考量是什么，比如为啥用了tomcat而不是resin、相关wiki、故障处理预案、常见故障、当前线上问题……等等 如果业务有单点，不接，让研发改造。如果运维的老板的老板强制要求，丑话说前头：因单点导致的问题，运维不背锅。 资产梳理正式准备接手，第一步，梳理资产。比如用到了哪些域名，这些域名对应哪些业务、哪些虚IP，分别是提供了什么服务、哪些机器，分别部署了什么模块、业务在哪些机房、用了多少带宽、总带宽情况、是否有其他业务共用争抢。 机器需要拿到更详尽的信息，比如机器配置、机架位、IP、管理卡IP等等，公司应该有个CMDB供查询。如果没有，运维同学，需要你去构建这个CMDB。 后面要考虑机器是否需要有备机、备件，机型是否可以统一。 基础监控知道有哪些资产了，就可以对这些资产做监控了，比如域名连通性监控/延迟监控、虚IP的连通性监控/延迟监控、机器宕机监控、机器硬件监控、sshd/crond等系统进程监控、系统运行的进程总数监控、系统参数配置监控，可以参看我之前的文章《完备的监控应覆盖什么》 服务梳理吃透之前串讲时给的架构图、数据流图、部署拓扑图。从运维层面，最好还要知道公司网络拓扑图。 了解每个模块的情况，部署在哪些机器上，部署在哪个目录，用什么账号启动的，日志打到哪里了，用什么语言编写的，怎么上线的，主要吃CPU资源还是内存还是磁盘还是IO，需要预留多少资源，平时利用率是多少，应该配置多大的阈值做监控，是否需要watchdog自动拉起，日志里出现哪些关键字需要报警，以及其他各种需要注意的问题。 业务监控基本的进程、端口存活性监控，机器利用率监控、日志关键字监控、日志不滚动监控、关联的服务的监控等等，后面会做API粒度的监控，来推动业务优化。 标准化改造机器命名方式、操作系统发行版、OS版本、第三方软件，比如jdk、tomcat、nginx，都要统一，做标准化方案。 服务扩容、变更、下线做一键化，每次升级只需要给个版本号即可，此时研发操作还是运维操作效果一样，故而可以交给研发上线，释放运维人力，权限要控制好。 重复的常规操作也要固化成脚本，一键完成。 梳理故障自愈场景，看平时有哪些故障的处理方式是固定的，抽象为脚本，报警之后自动触发，无人值守处理。 公司如果有一些基础设施，比如名字服务、MQ、日志平台，推动研发改造，将新服务接入。如果公司还没有这些基础设施，作为运维这个角色，可以着手搞起。 SOP梳理故障预案是一个非常重要的事情，线上没出故障之前，就应该提前去想，服务可能会出什么故障，如果真出了，应该如何处理，把处理步骤提前记录下来。毕竟，线上出故障的时候，人都比较紧张，直接看着预案处理，就踏实不少，不容易出错。 故障演练光有预案没有演练，是不靠谱的，没有经过验证的预案是不可信任的。所以，搞个放火演习，把模块搞挂试一把，把机器搞挂试一把，对线上稳定性绝对会有提升。 特别是研发说这个模块挂掉，可用性肯定没影响，OK，搞挂试试先。很可能会打他脸，-_-|| 有些场景演练是会有损的。这种场景还要不要演练？这个需要case by case的看，大部分情况都是要做演练会更好，毕竟，人在这盯着的时候出问题，比晚上睡着了出了问题要强太多。当然， 大规模基础网络故障这种演练，还是算了吧，通常的业务都是不具备机房级容灾的，呵呵 上面做完了，基本工作就完成了。上面很多事情都是一次性的，那未来的大把时间运维做啥？ 除了再花费部分时间做线上问题处理，我们应该把主要精力来提升业务产品力。做精细化运维，还记得运维九字真言么？“安全稳定高效低成本”，这就是我们的工作方向。下面举几个例子。 再谈业务监控上面谈到过一次业务监控，主要是一些通用的监控指标。我们对产品了解足够之后，应该做一些业务特有的监控，推动研发去做也可以，达到效果就好。 比如你运维了一个MQ，消息堆积量是需要监控滴；比如你运维了一个RPC服务，提供了三个接口，这三个接口的响应时长、成功率是需要监控滴；比如你运维了一个S3服务，每个桶的短期带宽增量你是需要监控滴；有那么点感觉了么？ :) API成功率、延迟统计在流量入口的nginx做所有业务线的所有API的成功率和延迟统计，是非常有必要的。把成功率比较低的TopN找出来，把延迟比较大的TopN找出来，让业务去优化。老板会喜欢这个的。 线上问题梳理整理线上所有问题，挨个解决，运维可以搞定的运维搞定，运维搞不定的找研发要排期，每周解决了多少问题，还有多少问题待解决，用周报的方式体现出来。 成本优化通过服务混部、或者统一的资源调度平台来节省机器资源，一台机器便宜的也好几万呢，这个事是比较容易有产出的。 容量规划容量规划和成本优化实际是紧密相关的，容量规划的重点是根据自然增量和运营需求，提前规划准备相应的容量，容量可能包括带宽、专线、网络设备、机器等等；当业务量下来的时候，可以腾挪相关资源支持其他业务线，让这些硬件尽量满负荷运转，物有所值。 业务精细化运维可以想出各种事情来搞，除了做这事，另一个需要长期投入的是构建运维基础平台，像什么监控系统、部署系统、产品库、资源利用率平台、域名管理、四七层接入配置平台、日志平台、Trace系统等等等等，嗯，其实运维还是挺忙的。 关于沟通最后说一点，接手一个新业务运维，势必与研发有各种沟通，每次沟通都要写会议纪要，发邮件出来，跟进人是谁，时间点是啥时候都要写明白，邮件发送双方团队邮件组，cc各方老大。事后关键节点做check，如未完成，线下沟通，达成一致后追此邮件给结论，说明延期原因以及新的时间点。如果沟通不畅，让老大去协调。]]></content>
      <categories>
        <category>职业规划</category>
      </categories>
      <tags>
        <tag>职业规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[完备的监控应覆盖什么？]]></title>
    <url>%2F2016%2F03%2F03%2F%E5%AE%8C%E5%A4%87%E7%9A%84%E7%9B%91%E6%8E%A7%E5%BA%94%E8%A6%86%E7%9B%96%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[对于一个互联网公司，要对哪些方面做了监控，才能称得上完备？今天笔者抛砖引玉，给出一个列表，不足之处，欢迎业界同仁补充，共同进步:)&emsp; 网络监控终端客户要想访问你的服务，势必要经过一系列网络链路，这是我们的第一个着眼点 网络质量全国各地，不同的地区，不同的运营商，访问你的网站的质量，比如延迟是多少，是否不通了 公网出口服务部署在某个IDC，IDC的公网出口是不是拥塞了，是不是断了 专线带宽服务可能是依赖其他服务的，而被依赖的服务却不在同一个机房，中间通过专线连通，那么专线的质量就需要关注了，典型的比如丢包情况，是否连通，带宽是否到达上限 网络设备各种交换机、路由器，是不是挂了，是不是丢包了，硬件是否故障了 机器监控这个大家通常不会忽略，毕竟你的服务是在机器上跑的嘛，简单唠叨一下 机器硬件比如磁盘是不是只读了，raid是不是故障了，内存是不是故障了，可以使用远程控制卡管理 机器运行态比如磁盘是不是满了，CPU是不是持续跑满，内存是不是快吃光了，IO持续100%，网卡是不是丢包了，系统进程总数是不是过多了，打开的文件句柄是不是过多了。 机器配置比如ulimit配置是否合理，一些系统参数比如nf_conntrack_max配置是否合理。 系统进程比如ntp是否工作正常，系统时间是否偏差太大，sshd进程是否工作正常，crond是否挂了 业务监控服务本身运行的情况，自然也是要监控的 存活性进程是否还在，端口是否还在监听，LOG是否不再滚动 异常日志比如抛了Exception，出现了ERROR、FATAL、ALERT等关键字 健康指标这个经常容易忽视，需要研发配合，能够反映服务自身健康状况的指标，跟业务自身相关。比如MQ，能够反映MQ健康状况的可能是消息堆积量。 接口监控服务对外提供的API，其成功率、延迟情况、QPS等等。一些人做的域名监控也可以归到这里。 周边依赖比如你依赖的其他服务是否健康，比如用到的HTTPS证书是否过期]]></content>
      <categories>
        <category>职业规划</category>
      </categories>
      <tags>
        <tag>职业规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Firewalld Rich and Direct Rules: Setting up RHEL 7 Server as a Router]]></title>
    <url>%2F2016%2F02%2F12%2FFirewalld-Rich-and-Direct-Rules-Setting-up-RHEL-7-Server-as-a-Router%2F</url>
    <content type="text"><![CDATA[Document links]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>route</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Setting up a MariaDB Server with SELinux on RHEL 7]]></title>
    <url>%2F2016%2F02%2F10%2FSetting-up-a-MariaDB-Server-with-SELinux-on-RHEL-7%2F</url>
    <content type="text"><![CDATA[Document links]]></content>
      <categories>
        <category>RHCE</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Configure Aggregated Network Links on RHEL 7: Bonding and Teaming]]></title>
    <url>%2F2016%2F02%2F06%2FConfigure-Aggregated-Network-Links-on-RHEL-7-Bonding-and-Teaming%2F</url>
    <content type="text"><![CDATA[Configure network bonding and teaming on RHEL 7. Aggregated Network LinksThere are two ways to configure aggregated network links on RHEL 7, via bonding or via teaming. Network bonding enables two or more network interfaces to act as one, simultaneously increasing the bandwidth and providing redundancy. Network teaming is designed to implement the concept in a different way by providing a small kernel driver to implement the fast handling of packet flows, and various user-space applications to do everything else in user space. The existing bonding driver is unaffected, network teaming is offered as an alternative and does not replace bonding in RHEL 7. Before We BeginWe have two virtual machines in our lab, with two network interfaces each. One machine will be configured for network bonding, and one for network teaming. Basic IPv6 configuration for network teaming will be covered. To avoid problems, we are going to configure networking from the console and not from Secure Shell (SSH). If we do something wrong, at least we won’t lose connectivity. Caveat for VirtualBoxFor those using VirtualBox to configure bonding or teaming, ensure that network adapters have promiscuous mode set to “Allow All”, and then enable promisc mode on the links, for example:12# ip link set eth0 promisc on# ip link set eth1 promisc on The above works OK for testing, but won’t persist after reboot. Either add to /etc/rc.local, or write a systemd service to handle it. Configure Network BondingEnsure that the bonding module is loaded:1# modprobe bonding While not required, feel free to check nmcli examples, where example 6 is about adding a bonding master and two slaves. You may find them useful.1# man 5 nmcli-examples A bond interface can be created with either the nmcli or the nmtui utilities. We use nmcli since we find it faster and easier to use. We are going to delete any existing network configuration to save ourselves some headache:1234# nmcli cNAME UUID TYPE DEVICEenp0s8 00cb8299-feb9-55b6-a378-3fdc720e0bc6 802-3-ethernet enp0s8enp0s17 8512e951-6012-c639-73b1-5b4d7b469f7f 802-3-ethernet enp0s17 We see that we have two network cards with predictable network interface names configured. Delete exiting configuration:1# nmcli c del enp0s8 enp0s17 Create a bonding interface named mybond0 with an active-backup mode:1# nmcli c add type bond ifname mybond0 con-name mybond0 mode active-backup]]></content>
      <categories>
        <category>RHCE</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一台电脑绑定多个GitHub帐号教程]]></title>
    <url>%2F2016%2F02%2F02%2F%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91%E7%BB%91%E5%AE%9A%E5%A4%9A%E4%B8%AAgithub%E5%B8%90%E5%8F%B7%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[思路ssh 方式链接到 Github，需要唯一的公钥，如果想同一台电脑绑定两个Github 帐号，需要两个条件: 1.能够生成两对 私钥/公钥 2.push 时，可以区分两个账户，推送到相应的仓库 解决方案:1.生成 私钥/公钥 时，密钥文件命名避免重复 2.设置不同 Host 对应同一 HostName 但密钥不同 3.取消 git 全局用户名/邮箱设置，为每个仓库独立设置 用户名/邮箱 操作方法1.查看已有 密钥 Mac 下输入命令 ls ~/.ssh/，看到 id_rsa 与 id_rsa_pub 则说明已经有一对密钥。 2.生成新的公钥，并命名为 id_rsa_2 (保证与之前密钥文件名称不同即可) ssh-keygen -t rsa -f ~/.ssh/id_rsa_2 -C &quot;yourmail@xxx.com&quot; 3.在 .ssh 文件夹下新建 config 文件并编辑，另不同 Host 实际映射到同一 HostName， 但密钥文件不同。Host 前缀可自定义，例子中wolf7 12345678910# default Host github.comHostName github.comUser gitIdentityFile ~/.ssh/id_rsa# rzxwang Host rzxwang.github.comHostName github.comUser gitIdentityFile ~/.ssh/id_rsa_2 4.将生成的 id_rsa.pub，id_rsa_2.pub内容copy 到对应的GitHub Repository SSH-KEY中 5.测试 ssh 链接 123456# 此处测试为默认配置，对应的KEY是id_rsassh -T git@github.com# 此处测试为rzxwang.github.com配置，对应的KEY是id_rsa_2ssh -T git@rzxwang.github.com# Hi rzxwang! You've successfully authenticated, but GitHub does not provide shell access.# 出现上边这句，表示链接成功 6.将项目 clone 到本地， folder-name 是本地文件夹路径 `git clone git@rzxwang.github.com:rzxwang/rzxwang.github.io.git wofl7.org` 7.取消全局 用户名/邮箱设置，并进入项目文件夹单独设置 123456# 取消全局 用户名/邮箱 配置git config –global –unset user.namegit config –global –unset user.email# 单独设置每个repo 用户名/邮箱git config user.email “xxxx@xx.com”git config user.name “xxxx” 8.命令行进入项目目录，重建 origin (rzxwang 为相应项目地址) 12git remote rm origingit remote add origin git@rzxwang.github.com:rzxwang/rzxwang.github.io.git 9.成功，可以 push 测试一下. 1git push origin master]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维蓝图思考]]></title>
    <url>%2F2015%2F01%2F02%2F%E8%BF%90%E7%BB%B4%E8%93%9D%E5%9B%BE%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[最近在做2015年规划，思考运维到底应该干哪些事，得出如下图表一张，欢迎各位同仁一起讨论。&emsp; 运维蓝图 定标准我们希望线上环境是统一的、干净的、规范的，所以就要定标准，比如： 机型：线上机型尽量少，省得光各种机型的备机就一大堆，浪费成本，针对少量机型做精，稳定性也更容易做 OS：比如统一CentOS6.8，统一kernel，统一各种优化配置，更安全，更稳定 第三方软件：比如MySQL、Tomcat、Nginx，尽量统一版本，统一扩展，统一部署方式，统一监控方式 发布标准：比如启停脚本，启动账号，LOG格式、切分方式，部署路径，watchdog 监控标准：制定指标黄页，机器、网络、业务程序、中间件等等都要如何监控，程序如何吐出反应自身健康状况的指标均要定规范 资源管理运维作为一个支撑性的部门，没办法赚钱，但可以省钱，把资源尽量合理利用起来，花更少的钱办更多的事 做好预算，容量规划，看业务增量得出预算机器量 各种机型需要备机配比，避免某机器坏了之后找不到备机可换 机器生命周期管理，流转流程，比如上线，下线，故障，借用等等 通过类似服务树这样的系统，分门别类的管理机器，知道每个机器的用途 通过类似Borg这样的统一调度系统，混部服务，提升资源利用率 监控监控作为运维的眼睛，稳定性的必要保障，必须要做好，做全面，做稳定，所有服务都挂了，监控不能挂 监控系统自身构建，监控数据量比较大，是运维系统中一个非常有难度的系统，可以参考的比如Borgmon、Gorilla、OpenTSDB、Zabbix+Grafana、Ganglia等 机器性能监控、基础环境监控、日志监控、网络监控、访问质量监控、业务监控，等等等等，没有最全，只有更全 部分问题报警之后，处理步骤是重复的固化的，这样的场景可以考虑故障自愈，无人值守自动处理，即使无法自动处理，也可以自动抓现场，提供后续分析依据 安全所谓安全无小事，安全直接关系到一个公司的存亡，有的公司会把安全团队放到运维部门下面，有的是单拎出来，不管组织结构怎么划分，安全都是运维一定要重点关注的 登录控制和操作审计，比如各个公司做的堡垒机、跳板机，控制哪些人可以登录哪些机器，而且所有操作均有记录，均可审计 安全接入，比如防DDOS，流量清洗，在公司所有服务之前，放置一道让人信赖的长城 服务安全，比如研发同学使用统一的框架，避免一些编码上的安全漏洞，再经常做一下漏洞扫描，扫扫更健康 灾难管理线上服务稳定性是运维同学的第一要务，灾难管理，是其中重要一环 首先服务架构本身，上线之前就要考虑好怎么做容灾，有单点的系统显然是过不了准入的，运维同学不能接 重要数据必须做好备份，只备份没演练可能会步了gitlab的后尘，所以定期演练必不可少，另外提前找好擅长数据恢复的伙伴，省得临时抱佛脚 线上所有变更操作，故障处理，需求处理都要有完善的SOP，新人来了，看着SOP，就可以搞定 宕机演练，定期巡检要常做，预料外的故障是我们最不希望看到的 访问质量公司做的业务如果是To C的，这块就重要了，互联网客户都没多少耐心，不要让客户感觉网站响应慢，这会直接导致客户流失 访问质量要做全国甚至全球监控，各个省市，各个主要链路，搞个大屏，全国用户访问质量清晰可见 通过CDN，图片优化，缓存策略，流量调度等等手段，让网站访问速度变成与友商竞争的一大优势 变更管理对线上做变更，是导致线上问题的一大源头，这块要单独拎出来说说 系统组交付机器之后，首先要根据自身业务特点做一次初始化，对操作系统做一些配置，安装一些必要的软件，比如机器挂载到服务树自动触发初始化策略 大点的公司，每天几千次发布很正常，有个部署平台很重要，历史版本要可回溯，一键回滚，支持各种策略各种并发度上线，具备分发大文件到几万甚至几十万台机器的能力 关联关系类型的配置可以采用统一的名字服务解决，开关类的配置可以采用中心化配置中心或者采用一次发布解决，每个程序如果都支持reload配置倒是不错 编程框架编程框架好像跟运维无关，实则不然。统一的编程框架会让运维复杂度降低，还可以在框架中嵌入运维逻辑，不考虑运维的架构师不是好架构师 统一RPC框架，统一重试策略，统一名字服务，统一配置管理，统一watchdog，统一监控方式，统一日志打印… 多环境支持：开发环境，单测环境，集测环境，小流量环境，线上环境…用同一个发布包上线，搞定配置不同的问题 服务治理方面，比如接口权限控制，接口版本管理，流控，路由规则，等等 自动化平台运维这个行当，不是一个console一个pash就万事大吉的，也需要相关系统的支持，提高工作效率，提高稳定性 发布之前：版本管理系统，比如gitlab、编译打包平台、制品管理仓库 发布中：机器管理分组系统，部署系统，大文件分发工具 发布之后：监控系统，资源利用率平台 日常工作：初始化平台来初始化操作系统，跳板机、堡垒机控制登录，工单系统等等 结语如果一个公司注重服务稳定性、安全性，注重成本控制，那就应该注重运维，这群默默工作在服务背后的背锅侠，请珍惜！]]></content>
      <categories>
        <category>职业规划</category>
      </categories>
      <tags>
        <tag>职业规划</tag>
      </tags>
  </entry>
</search>
